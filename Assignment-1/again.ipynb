{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.utils import to_categorical # FIX ask if this is allowed\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier # for hyperparam tuning only\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "assert X_train.shape == (50000, 32, 32, 3)\n",
    "assert X_test.shape == (10000, 32, 32, 3)\n",
    "assert y_train.shape == (50000, 1)\n",
    "assert y_test.shape == (10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train/255, X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shapes:\n",
      "X_train: (42500, 32, 32, 3)\n",
      "y_train: (42500, 1)\n",
      "\n",
      "Validation set shapes:\n",
      "X_val: (7500, 32, 32, 3)\n",
      "y_val: (7500, 1)\n",
      "\n",
      "Test set shapes:\n",
      "X_test: (10000, 32, 32, 3)\n",
      "y_test: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42, stratify=y_train)\n",
    "print(\"Training set shapes:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"\\nValidation set shapes:\")\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"y_val:\", y_val.shape)\n",
    "print(\"\\nTest set shapes:\")\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(kernel_init = 'he_uniform', drop_out_value = 0.2, learning_rate_schedule = 'exponential'):\n",
    "    '''A function to create the mlp model'''\n",
    "    model_mlp = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape = [32, 32, 3]),\n",
    "        keras.layers.Dropout(rate = drop_out_value),\n",
    "        keras.layers.Dense(1500, activation = \"relu\", kernel_initializer = kernel_init),\n",
    "        keras.layers.Dropout(rate = drop_out_value),\n",
    "        keras.layers.Dense(1000, activation = \"relu\", kernel_initializer = kernel_init),\n",
    "        keras.layers.Dropout(rate = drop_out_value),\n",
    "        keras.layers.Dense(500, activation = \"relu\", kernel_initializer = kernel_init),\n",
    "        keras.layers.Dropout(rate = drop_out_value),\n",
    "        keras.layers.Dense(10, activation = \"softmax\")\n",
    "    ])\n",
    "\n",
    "    if learning_rate_schedule == 'power':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate = 0.01, decay = 1e-4)\n",
    "    elif learning_rate_schedule == 'exponential':\n",
    "        s = 100 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "        learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "        optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model_mlp.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can not find the MLP model in current dir!\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 3072)              0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1500)              4609500   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1500)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1000)              1501000   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 500)               500500    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6616010 (25.24 MB)\n",
      "Trainable params: 6616010 (25.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-03 21:29:43.069433: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1329/1329 [==============================] - ETA: 0s - loss: 3.2009 - accuracy: 0.2109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-03 21:30:05.574547: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1329/1329 [==============================] - 24s 16ms/step - loss: 3.2009 - accuracy: 0.2109 - val_loss: 2.7455 - val_accuracy: 0.2255\n",
      "Epoch 2/100\n",
      "1329/1329 [==============================] - 17s 13ms/step - loss: 2.4542 - accuracy: 0.2525 - val_loss: 3.0099 - val_accuracy: 0.2149\n",
      "Epoch 3/100\n",
      "1329/1329 [==============================] - 17s 12ms/step - loss: 2.4187 - accuracy: 0.2557 - val_loss: 6.3834 - val_accuracy: 0.1552\n",
      "Epoch 4/100\n",
      "1329/1329 [==============================] - 17s 13ms/step - loss: 2.8244 - accuracy: 0.2430 - val_loss: 7.3319 - val_accuracy: 0.1311\n",
      "Epoch 5/100\n",
      "1329/1329 [==============================] - 16s 12ms/step - loss: 3.7812 - accuracy: 0.2240 - val_loss: 8.2117 - val_accuracy: 0.1121\n",
      "Epoch 6/100\n",
      "1329/1329 [==============================] - 19s 14ms/step - loss: 6.2866 - accuracy: 0.2076 - val_loss: 28.4749 - val_accuracy: 0.1059\n",
      "Epoch 7/100\n",
      "1329/1329 [==============================] - 17s 13ms/step - loss: 11.0960 - accuracy: 0.2033 - val_loss: 41.0877 - val_accuracy: 0.1095\n",
      "Epoch 8/100\n",
      "1329/1329 [==============================] - 17s 13ms/step - loss: 19.2260 - accuracy: 0.1985 - val_loss: 48.5910 - val_accuracy: 0.1512\n",
      "Epoch 9/100\n",
      "1193/1329 [=========================>....] - ETA: 1s - loss: 30.9833 - accuracy: 0.1992"
     ]
    }
   ],
   "source": [
    "if os.path.exists('Zhang_Hanlin-MLP'):\n",
    "    #model_mlp = keras.models.model_from_json(json.dumps('Zhang_Hanlin-MLP'))\n",
    "    model_mlp = tf.keras.models.load_model('Zhang_Hanlin-MLP')\n",
    "    model_mlp.summary()\n",
    "    #model_mlp.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "    history_mlp = model_mlp.fit(X_train, y_train, epochs = 1, validation_data = (X_val, y_val), callbacks = [early_stopping])\n",
    "else:\n",
    "    print(\"Can not find the MLP model in current dir!\")\n",
    "    model_mlp = create_mlp(kernel_init = 'he_uniform', drop_out_value = 0.2, learning_rate_schedule = 'exponential')\n",
    "    model_mlp.summary()\n",
    "    mlp_start = time.time()\n",
    "    history_mlp = model_mlp.fit(X_train, y_train, epochs = 100, validation_data = (X_val, y_val), callbacks = [early_stopping])\n",
    "    mlp_end = time.time()\n",
    "    model_mlp.save('Zhang_Hanlin-MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
